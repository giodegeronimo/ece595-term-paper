\section{Paper Summaries}
\label{sec:summaries}

% One paragraph per paper. Factual, descriptive, no critique yet.

%-------------------------------------------------------------------------
\subsection{Rectified Flow (Liu et al., 2023)}

Describe the problem of inefficient sampling in diffusion models.
Summarize the proposed rectified probability flow formulation.
Explain the training setup and the deterministic ODE sampling procedure.
State reported improvements in sample quality and sampling speed.

%-------------------------------------------------------------------------
\subsection{FACT (Lu and Elhamifar, 2024)}

Describe the frame-wise action segmentation task.
Summarize the Frame-Action Cross Attention mechanism.
Explain learned action tokens and temporal modeling rationale.
State reported improvements in efficiency and accuracy.

%-------------------------------------------------------------------------
\subsection{NaViT (Dehghani et al., 2023)}

The long-standing practice in computer vision has been to pad or resize every image to a fixed shape before feeding it into a model, which either wastes compute (padding) or throws away useful spatial cues (resizing). NaViT \cite{dehghani2023navit} instead makes ViTs resolution-agnostic by packing variable-resolution images into shared sequences. A greedy algorithm fills each sequence until a token budget is reached, unused slots (pad tokens) are minimal ($<2\%$ of tokens), and attention masks ensure each image's tokens only see one another. Factorized positional embeddings encode height and width separately so the model understands aspect ratios, and variable token dropping lets larger images shed more patches during pretraining to balance compute. Coupled with random resolution sampling, this recipe delivers better accuracy than a vanilla ViT at comparable compute while training up to 4x faster, showing that native-resolution training can be both efficient and effective. The authors summarize their findings as: (i) random resolution sampling slashes training cost, (ii) NaViT achieves strong accuracy over a broad resolution range so inference cost can be dialed post hoc, and (iii) fixed batch shapes from packing enable new knobs such as aspect-ratio-preserving sampling, variable token dropping, and adaptive computation.
%-------------------------------------------------------------------------
\subsection{Mask2Former (Cheng et al., 2022)}

Mask2Former \cite{cheng2022mask2former} shows that semantic, instance, and panoptic segmentation can all be framed as predicting $N$ binary masks with $N$ labels, so it learns a single architecture that does exactly that. Images pass through a CNN backbone and pixel decoder to produce multi-scale features, and a pool of learned mask queries runs through transformer decoder layers that see progressively higher-resolution image features. Each query outputs a class logit and a mask logit via a dot-product with the full-resolution features, so the same query embedding decides “what” and “where.” Masked attention keeps each query focused on its current region, while the multi-scale ladder helps recover tiny structures. The authors also sub-sample pixels when computing mask loss, which cuts memory overhead without hurting accuracy. Across COCO panoptic, ADE20K semantic, and Cityscapes instance benchmarks, this universal design matches or beats task-specific models, giving a single set of weights that works everywhere.
