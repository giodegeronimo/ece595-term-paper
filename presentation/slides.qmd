---
title: "ECE 595 Presentation"
author: "Giovanni De Geronimo"
format: 
    revealjs:
        margin: 0.04
        theme: simple
        highlight-style: github
        css: slides.css
---
## Agenda
- Motivation and goal
- Three paper snapshots: 
  - **Mask2Former**
  - **NaViT**
  - **Rectified Flow**
- Non-Trivial Implementation

## Motivation
- Why these three papers?
<br></br>
- **Mask2Former**: unified segmentation via mask queries
- **NaViT**: packed ViTs for native-resolution training
- **Rectified Flow**: straight probability paths for fast image generation

## Mask2Former - What They Did
:::{.columns .vcenter}
:::{.column width="50%"}
::: {.smallish-text}
<br></br>
- Key idea: universal mask queries for semantic/instance/panoptic tasks
<br></br>
- Dataflow:
  - Images passed through backbone to extract low level features
  - Pixel decoder progressively upsamples the features back to the original image shape
  - Learned queries --> transformer decoders w/ masked cross-attention (k/v from image features)
  - Queries get dotted with full-resolution features to create masks and labels 
:::
:::
:::{.column width="50%"}
![](../figures/mask2former_flow.png){width=100% .center-image}
<div class="caption">Mask2Former dataflow</div>
:::
:::

## Mask2Former Results & Impact
::: {.small-text}
- One unified model outperforms specialized models in segmentation tasks
:::
::: {.image-block}
![](../figures/mask2former_comparisons.png){width=50% .center-image}
<div class="caption">Mask2Former comparisons</div>
:::
::: {.small-text}
- Got 3X memory savings by calculating mask loss on smaller random sample of pixels
:::

## NaViT – What They Did
:::{.columns}
:::{.column width="35%"}
::: {.small-text}
- Key idea: packed variable-resolution ViTs with masked attention scope
- Dataflow: greedy packing, per-image attention masks, factorized embeddings, token dropping
:::
:::
:::{.column width="65%"}
::: {.image-block}
![](../figures/NaViT_flow.png){width=100%}
<div class="caption">NaViT packing schematic</div>
:::
:::
:::

## NaViT Results & Impact
:::{.small-text}
- Compute savings (TPU hours), accuracy across resolution range
:::
:::{.image-block}
![](../figures/NaViT_plots.png){width=70%}
<div class="caption">NaViT compute/accuracy plots</div>
:::
:::{.small-text}
- Smooth cost/acc trade-off at inference
- No need to lose information by resizing images
:::


## Rectified Flow – What They Did
- Treat image generation as a neural ODE for transport between distributions
- Key idea: straightening probability paths for faster sampling
- Target:
<div class="smallish-text">
$$
\min_{v} \int_{0}^{1} \mathbb{E}\!\left[
  \left\| (X_{1} - X_{0}) - v(X_{t}, t) \right\|^{2}
\right] \, dt,
\quad\text{where } X_t = (1 - t)X_0 + tX_1
$$
</div>
- Model learns a vector field to transport distributions

## Rectified Flow – What They Did Cont.
- This induces a rerouting of the flow to make the ODE well defined
- Repeating this straightens the flow
  ![](../figures/fsaf_flows.png){width=100%}
<div class="caption">Rectified Flow Straightening</div>
- Straight flow = faster generation

## Rectified Flow Results & Impact
::: {.smaller-text}
- Significantly faster sampling: ODE integrates in few steps
:::
:::{.columns .vcenter}
:::{.column width="40%"}
::: {.image-block}
![](../figures/fsaf_zplot.png){width=80%}
<div class="caption">Straight vs. zig-zag paths</div>
:::
:::
:::{.column width="60%"}
::: {.image-block}
![](../figures/fsaf_cats.png){width=90%}
<div class="caption">Rectified Flow samples</div>
:::
:::
:::

## Implementation Overview
:::{.columns}
:::{.column width="55%"}
- Paper: Rectified Flow
- Model Architecture: ViT
  - Fourier Embeddings for t
  - Factorized Positional Embeddings
- Dataset: AFHQ Cats
- Training: My laptop
:::
:::{.column width="45%"}
::: {.image-block}
![](../figures/cats_ds.png){width=65%}
<div class="caption">Dataset Images</div>
:::
:::
:::

## Preliminary Results
::: {.image-block}
![](../figures/0_vs_1rect_1.png){width=80%}
![](../figures/0_vs_1rect_2.png){width=80%}
<div class="caption">No Rectify vs 1 Rectify</div>
:::

## Bonus: Add NaViT
::: {.image-block}
![](../figures/NaViT_rf_samp1.png){width=23%}
![](../figures/NaViT_rf_samp2.png){width=23%}
<div class="caption">NaViT Generations</div>
:::

## Next Steps
- Evaluate NaViT version vs no NaViT to see if we get those efficiency gains
<br></br>
- Train with more compute to get higher res images
<br></br>
- Play around with the fact that the flow can be reversed

## Thank You
- Questions?
