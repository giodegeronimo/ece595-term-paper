{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import and hyperparams\n",
    "'''\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import navit_rf as nrf\n",
    "from navit_rf import make_packing_collate, sample_rectified_flow, random_resized_transform\n",
    "\n",
    "# --- paths ---\n",
    "DATA_ROOT = Path(\"../../../cat/\")        # change me\n",
    "CKPT_DIR = Path(\"experiments/navit_rf/outputs/checkpoints\")\n",
    "SAMPLE_DIR = Path(\"experiments/navit_rf/outputs/samples\")\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SAMPLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- hyperparameters ---\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4\n",
    "EPOCHS = 2000\n",
    "PRINT_EVERY = 25         # batches between loss prints\n",
    "SAMPLE_EVERY = 3        # epochs between generations\n",
    "NOISE_STD = 1.0          # matches Gaussian anchor\n",
    "N_SAMPLE_IMAGES = 8\n",
    "SIZES = [\n",
    "    (32, 32),\n",
    "    (36, 36),\n",
    "    (40, 40),\n",
    "    (44, 44),\n",
    "    (48, 48),\n",
    "    (52, 52),\n",
    "    (60, 60),\n",
    "    (64, 64),\n",
    "]\n",
    "SAMPLER_STEPS = 50\n",
    "PATCH_SIZE = 4\n",
    "MAX_TOKENS_PER_PACK = 256\n",
    "DEVICE = 'mps'#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "LOG_ROOT = Path(\"experiments/navit_rf/logs\")\n",
    "LOG_DIR = LOG_ROOT / timestamp\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TRAIN_LOSS_FILE = LOG_DIR / \"training_loss.csv\"\n",
    "TRAIN_LOSS_FILE.write_text(\"epoch,loss\\n\")\n",
    "config = {\n",
    "    'data_root': str(DATA_ROOT),\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'lr': LR,\n",
    "    'epochs': EPOCHS,\n",
    "    'noise_std': NOISE_STD,\n",
    "    'patch_size': PATCH_SIZE,\n",
    "    'max_tokens_per_pack': MAX_TOKENS_PER_PACK,\n",
    "    'device': str(DEVICE),\n",
    "}\n",
    "(LOG_DIR / 'config.json').write_text(json.dumps(config, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = nrf.gather_image_paths(DATA_ROOT)\n",
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset, Dataloader, Optimizer\n",
    "'''\n",
    "\n",
    "img_paths = nrf.gather_image_paths(DATA_ROOT)\n",
    "transform = random_resized_transform(\n",
    "    noise_std=NOISE_STD,\n",
    "    scale_range=(0.0625, 0.125),  # scales H and W by the same factor, keeps aspect ratio\n",
    ")\n",
    "dataset = nrf.ImageDataset(img_paths, transform=transform)\n",
    "\n",
    "collate_fn = make_packing_collate(\n",
    "    patch_size=PATCH_SIZE,\n",
    "    max_tokens_per_pack=MAX_TOKENS_PER_PACK,\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "model = nrf.ViTVelocity(\n",
    "    patch=PATCH_SIZE,\n",
    "    in_ch=3,\n",
    "    d_model=512,\n",
    "    depth=8,\n",
    "    n_head=8,\n",
    "    mlp_ratio=4.0,\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_2.pth', map_location='mps'))\n",
    "samples = sample_rectified_flow(\n",
    "    model,\n",
    "    n=N_SAMPLE_IMAGES,\n",
    "    device=DEVICE,\n",
    "    img_size=None,  # uses current padded size\n",
    "    steps=20,\n",
    "    shapes = SIZES\n",
    ")\n",
    "grid_path = SAMPLE_DIR / f\"samples_epoch{0:04d}.png\"\n",
    "save_image(samples, grid_path, nrow=int(math.sqrt(N_SAMPLE_IMAGES)), normalize=False)\n",
    "print(f\"Saved samples to {grid_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        '''\n",
    "        Training\n",
    "        '''\n",
    "        global_step = 0\n",
    "        for epoch in range(1, EPOCHS + 1):\n",
    "            model.train()\n",
    "            running = 0.0\n",
    "            total = 0.0\n",
    "            steps = 0\n",
    "\n",
    "            for step, batch in enumerate(dataloader, start=1):\n",
    "                steps = step\n",
    "                images = batch[\"images\"].to(DEVICE)\n",
    "                patch_hw = batch[\"patch_hw\"].to(DEVICE)\n",
    "                packs = batch[\"packs\"]\n",
    "\n",
    "                x0 = torch.randn_like(images) * NOISE_STD\n",
    "                t = torch.rand(images.size(0), device=DEVICE)\n",
    "                xt = nrf.utils.linear_probability_path(x0, images, t)\n",
    "                target = nrf.utils.velocity_target(x0, images)\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                preds = model(xt, t, patch_hw=patch_hw, packs=packs)\n",
    "                loss = criterion(preds, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running += loss.item()\n",
    "                total += loss.item()\n",
    "                global_step += 1\n",
    "                if step % PRINT_EVERY == 0:\n",
    "                    avg = running / PRINT_EVERY\n",
    "                    print(f\"[epoch {epoch}/{EPOCHS}] step {step}: loss = {avg:.4f}\")\n",
    "                    running = 0.0\n",
    "\n",
    "            epoch_loss = total / max(steps, 1)\n",
    "            with open(TRAIN_LOSS_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"{epoch},{epoch_loss:.6f}\n",
    "\")\n",
    "\n",
    "            ckpt_path = CKPT_DIR / f\"vit_velocity_epoch{epoch:04d}.pth\"\n",
    "            torch.save(\n",
    "                {\"epoch\": epoch, \"model\": model.state_dict(), \"optimizer\": optimizer.state_dict()},\n",
    "                ckpt_path,\n",
    "            )\n",
    "            print(f\"Saved checkpoint to {ckpt_path}\")\n",
    "\n",
    "            if epoch % SAMPLE_EVERY == 0:\n",
    "                samples = sample_rectified_flow(\n",
    "                    model,\n",
    "                    n=N_SAMPLE_IMAGES,\n",
    "                    device=DEVICE,\n",
    "                    img_size=None,\n",
    "                    steps=20,\n",
    "                    shapes=SIZES,\n",
    "                )\n",
    "                grid_path = SAMPLE_DIR / f\"samples_epoch{epoch:04d}.png\"\n",
    "                save_image(samples, grid_path, nrow=int(math.sqrt(N_SAMPLE_IMAGES)), normalize=False)\n",
    "                print(f\"Saved samples to {grid_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
