{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76945ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import and hyperparams\n",
    "'''\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import navit_rf as nrf\n",
    "from navit_rf import make_packing_collate, sample_rectified_flow, random_resized_transform\n",
    "\n",
    "# --- paths ---\n",
    "DATA_ROOT = Path(\"/path/to/your/images\")        # change me\n",
    "CKPT_DIR = Path(\"experiments/navit_rf/outputs/checkpoints\")\n",
    "SAMPLE_DIR = Path(\"experiments/navit_rf/outputs/samples\")\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SAMPLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- hyperparameters ---\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4\n",
    "EPOCHS = 20\n",
    "PRINT_EVERY = 50         # batches between loss prints\n",
    "SAMPLE_EVERY = 5         # epochs between generations\n",
    "NOISE_STD = 1.0          # matches Gaussian anchor\n",
    "N_SAMPLE_IMAGES = 8\n",
    "SAMPLER_STEPS = 100\n",
    "PATCH_SIZE = 8\n",
    "MAX_TOKENS_PER_PACK = 512\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8078fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset, Dataloader, Optimizer\n",
    "'''\n",
    "\n",
    "img_paths = nrf.gather_image_paths(DATA_ROOT)\n",
    "transform = random_resized_transform(\n",
    "    noise_std=NOISE_STD,\n",
    "    scale_range=(0.2, 1.0),  # scales H and W by the same factor, keeps aspect ratio\n",
    ")\n",
    "dataset = nrf.ImageDataset(img_paths, transform=transform)\n",
    "\n",
    "collate_fn = make_packing_collate(\n",
    "    patch_size=PATCH_SIZE,\n",
    "    max_tokens_per_pack=MAX_TOKENS_PER_PACK,\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "model = nrf.ViTVelocity(\n",
    "    patch=PATCH_SIZE,\n",
    "    in_ch=3,\n",
    "    d_model=256,\n",
    "    depth=8,\n",
    "    n_head=8,\n",
    "    mlp_ratio=4.0,\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18947a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training\n",
    "'''\n",
    "global_step = 0\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "\n",
    "    for step, batch in enumerate(dataloader, start=1):\n",
    "        images = batch[\"images\"].to(DEVICE)\n",
    "        patch_hw = batch[\"patch_hw\"].to(DEVICE)\n",
    "        packs = batch[\"packs\"]\n",
    "\n",
    "        x0 = torch.randn_like(images) * NOISE_STD\n",
    "        t = torch.rand(images.size(0), device=DEVICE)\n",
    "        xt = nrf.linear_probability_path(x0, images, t)\n",
    "        target = nrf.velocity_target(x0, images)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        preds = model(xt, t, patch_hw=patch_hw, packs=packs)\n",
    "        loss = criterion(preds, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running += loss.item()\n",
    "        global_step += 1\n",
    "        if step % PRINT_EVERY == 0:\n",
    "            avg = running / PRINT_EVERY\n",
    "            print(f\"[epoch {epoch}/{EPOCHS}] step {step}: loss = {avg:.4f}\")\n",
    "            running = 0.0\n",
    "\n",
    "    ckpt_path = CKPT_DIR / f\"vit_velocity_epoch{epoch:04d}.pth\"\n",
    "    torch.save(\n",
    "        {\"epoch\": epoch, \"model\": model.state_dict(), \"optimizer\": optimizer.state_dict()},\n",
    "        ckpt_path,\n",
    "    )\n",
    "    print(f\"Saved checkpoint to {ckpt_path}\")\n",
    "\n",
    "    if epoch % SAMPLE_EVERY == 0:\n",
    "        samples = sample_rectified_flow(\n",
    "            model,\n",
    "            n=N_SAMPLE_IMAGES,\n",
    "            device=DEVICE,\n",
    "            img_size=images.shape[-1],  # uses current padded size\n",
    "            steps=SAMPLER_STEPS,\n",
    "        )\n",
    "        grid_path = SAMPLE_DIR / f\"samples_epoch{epoch:04d}.png\"\n",
    "        save_image(samples, grid_path, nrow=int(math.sqrt(N_SAMPLE_IMAGES)), normalize=False)\n",
    "        print(f\"Saved samples to {grid_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
